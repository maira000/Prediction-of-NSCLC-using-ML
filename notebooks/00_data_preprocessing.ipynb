{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6265a2d3",
   "metadata": {},
   "source": [
    "# 00 Data Preprocessing\n",
    "\n",
    "## Importing Required Libraries\n",
    "We begin by importing the fundamental Python libraries required for data handling and numerical computations:  \n",
    "\n",
    "- **pandas** → used for data manipulation and analysis (loading `.csv` files, handling tables).  \n",
    "- **numpy** → provides support for mathematical operations and numerical computations.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a8d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584e66db",
   "metadata": {},
   "source": [
    "## Importing Visualization Library\n",
    "\n",
    "To visualize our dataset and model outputs, we use **Matplotlib**.  \n",
    "Specifically, the `pyplot` sub-library provides functions for creating plots such as line charts, scatter plots, heatmaps, and more.  \n",
    "\n",
    "This will later help us in visualizing **t-SNE plots, confusion matrices, and ROC curves**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f336b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # pyplot is the sub-library of matplotlib used for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf0f446",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "We load the processed dataset (`datafile.csv`) into a Pandas DataFrame.  \n",
    "The dataset originates from the **GEO database (GSE81089)** and contains **gene expression profiles** for NSCLC samples,  \n",
    "which were converted from `.tsv` format into `.csv` for easier handling in Python.\n",
    "\n",
    "- The variable `df` will store our dataset in tabular form.  \n",
    "- Each row corresponds to a sample, and each column represents a gene feature or phenotype label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37c911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/datafile.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c28e47c",
   "metadata": {},
   "source": [
    "## Exploring the Dataset\n",
    "\n",
    "After loading the dataset, it is important to **inspect its structure** to understand:\n",
    "\n",
    "- The type of object (`DataFrame`) we are working with.  \n",
    "- Number of rows and columns.  \n",
    "- Total number of elements.  \n",
    "- Column names, data types, and presence of missing values.  \n",
    "- A preview of the first few samples.\n",
    "\n",
    "These steps help ensure that the dataset is loaded correctly and ready for preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c614d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 218 entries, 0 to 217\n",
      "Columns: 18986 entries, ENSG00000000003 to Labels\n",
      "dtypes: float64(18209), int64(776), object(1)\n",
      "memory usage: 31.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>ENSG00000001460</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000272537</th>\n",
       "      <th>ENSG00000272538</th>\n",
       "      <th>ENSG00000272539</th>\n",
       "      <th>ENSG00000272540</th>\n",
       "      <th>ENSG00000272541</th>\n",
       "      <th>ENSG00000272542</th>\n",
       "      <th>ENSG00000272543</th>\n",
       "      <th>ENSG00000272544</th>\n",
       "      <th>ENSG00000272545</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.1950</td>\n",
       "      <td>43.8616</td>\n",
       "      <td>14.71010</td>\n",
       "      <td>4.81335</td>\n",
       "      <td>7.40831</td>\n",
       "      <td>112.4260</td>\n",
       "      <td>43.9196</td>\n",
       "      <td>12.12890</td>\n",
       "      <td>13.3027</td>\n",
       "      <td>6.53823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.38909</td>\n",
       "      <td>0.312571</td>\n",
       "      <td>0.086774</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.8891</td>\n",
       "      <td>47.0457</td>\n",
       "      <td>7.81233</td>\n",
       "      <td>5.92073</td>\n",
       "      <td>9.83188</td>\n",
       "      <td>39.7146</td>\n",
       "      <td>60.4056</td>\n",
       "      <td>9.20525</td>\n",
       "      <td>19.6343</td>\n",
       "      <td>2.65372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.15011</td>\n",
       "      <td>0.050841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.1910</td>\n",
       "      <td>38.1292</td>\n",
       "      <td>12.31170</td>\n",
       "      <td>8.21385</td>\n",
       "      <td>9.68575</td>\n",
       "      <td>25.9596</td>\n",
       "      <td>49.0519</td>\n",
       "      <td>23.92220</td>\n",
       "      <td>20.1660</td>\n",
       "      <td>9.99002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.11998</td>\n",
       "      <td>0.551958</td>\n",
       "      <td>0.036071</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.0324</td>\n",
       "      <td>54.3030</td>\n",
       "      <td>8.41631</td>\n",
       "      <td>6.71221</td>\n",
       "      <td>10.92630</td>\n",
       "      <td>80.2073</td>\n",
       "      <td>40.4700</td>\n",
       "      <td>46.93690</td>\n",
       "      <td>20.1807</td>\n",
       "      <td>5.55931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.34570</td>\n",
       "      <td>0.319958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086684</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.9686</td>\n",
       "      <td>51.2969</td>\n",
       "      <td>8.84999</td>\n",
       "      <td>4.79088</td>\n",
       "      <td>8.36149</td>\n",
       "      <td>38.4429</td>\n",
       "      <td>58.1048</td>\n",
       "      <td>15.60820</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>5.53239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.61839</td>\n",
       "      <td>0.415423</td>\n",
       "      <td>0.041381</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095240</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18986 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENSG00000000003  ENSG00000000419  ENSG00000000457  ENSG00000000460  \\\n",
       "0          52.1950          43.8616         14.71010          4.81335   \n",
       "1          37.8891          47.0457          7.81233          5.92073   \n",
       "2          23.1910          38.1292         12.31170          8.21385   \n",
       "3          25.0324          54.3030          8.41631          6.71221   \n",
       "4          41.9686          51.2969          8.84999          4.79088   \n",
       "\n",
       "   ENSG00000000938  ENSG00000000971  ENSG00000001036  ENSG00000001084  \\\n",
       "0          7.40831         112.4260          43.9196         12.12890   \n",
       "1          9.83188          39.7146          60.4056          9.20525   \n",
       "2          9.68575          25.9596          49.0519         23.92220   \n",
       "3         10.92630          80.2073          40.4700         46.93690   \n",
       "4          8.36149          38.4429          58.1048         15.60820   \n",
       "\n",
       "   ENSG00000001167  ENSG00000001460  ...  ENSG00000272537  ENSG00000272538  \\\n",
       "0          13.3027          6.53823  ...              0.0                0   \n",
       "1          19.6343          2.65372  ...              0.0                0   \n",
       "2          20.1660          9.99002  ...              0.0                0   \n",
       "3          20.1807          5.55931  ...              0.0                0   \n",
       "4          23.3442          5.53239  ...              0.0                0   \n",
       "\n",
       "   ENSG00000272539  ENSG00000272540  ENSG00000272541  ENSG00000272542  \\\n",
       "0                0          1.38909         0.312571         0.086774   \n",
       "1                0          1.15011         0.050841         0.000000   \n",
       "2                0          1.11998         0.551958         0.036071   \n",
       "3                0          4.34570         0.319958         0.000000   \n",
       "4                0          2.61839         0.415423         0.041381   \n",
       "\n",
       "   ENSG00000272543  ENSG00000272544  ENSG00000272545  Labels  \n",
       "0                0              0.0         0.000000   Tumor  \n",
       "1                0              0.0         0.000000   Tumor  \n",
       "2                0              0.0         0.000000   Tumor  \n",
       "3                0              0.0         0.086684   Tumor  \n",
       "4                0              0.0         0.095240   Tumor  \n",
       "\n",
       "[5 rows x 18986 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the type of the object\n",
    "type(df)\n",
    "\n",
    "# Summary info: column names, non-null counts, data types\n",
    "df.info()\n",
    "\n",
    "# Total number of elements in the DataFrame\n",
    "df.size\n",
    "\n",
    "# Number of rows and columns\n",
    "df.shape\n",
    "\n",
    "# Preview first 5 rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604f5be",
   "metadata": {},
   "source": [
    "## Encoding Labels and Preparing Features\n",
    "\n",
    "Machine learning models require **numerical inputs**. Therefore, we need to:\n",
    "\n",
    "1. Encode the **phenotype labels** (`Normal` and `Tumor`) into numerical form using `LabelEncoder` from `scikit-learn`.  \n",
    "   - `Normal` → 0  \n",
    "   - `Tumor` → 1  \n",
    "\n",
    "2. Verify the unique classes and their counts to ensure correct encoding.\n",
    "\n",
    "3. Separate the dataset into:  \n",
    "   - `X` → feature matrix (all gene expression columns)  \n",
    "   - `y` → target labels (encoded NSCLC phenotypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afac579b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels\n",
      "1    199\n",
      "0     19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['Labels'] = label_encoder.fit_transform(df['Labels'])\n",
    "df['Labels'].unique()\n",
    "#counting the number of classes\n",
    "df[\"Labels\"].value_counts()\n",
    "print(df[\"Labels\"].value_counts())\n",
    "#Assigning the numerical data to a \"X\" variable and labels column into a \"y\" variable that will be used in the next steps\n",
    "X = df.iloc[:,:-1]\n",
    "y = df[\"Labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6cd03f",
   "metadata": {},
   "source": [
    "## Data Splitting, Scaling, and Normalization\n",
    "\n",
    "Before training machine learning models, we need to prepare the data:\n",
    "\n",
    "1. **Train-Test Split**:  \n",
    "   - Divide the dataset into training and testing sets using `train_test_split`  \n",
    "   - `70%` for training and `30%` for testing  \n",
    "   - `random_state=42` ensures reproducibility\n",
    "\n",
    "2. **Standardization**:  \n",
    "   - Features are scaled to have **zero mean** and **unit variance** using `StandardScaler`  \n",
    "   - This helps models converge faster and improves performance, especially for distance-based algorithms like SVM.\n",
    "\n",
    "3. **Handling Missing Values**:  \n",
    "   - Fill any missing values in `X` with the **column mean** to avoid errors during training.\n",
    "\n",
    "4. **Optional Normalization**:  \n",
    "   - For large-scale values, we normalize features to keep them on a similar scale, which improves numerical stability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d10229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test ,Y_train, Y_test = train_test_split(X,y,test_size =0.30, random_state=42)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "#filling up missing values\n",
    "X = X.fillna(X.mean())\n",
    "#normalizing for large values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27235874",
   "metadata": {},
   "source": [
    "## Train-Test Split and Feature Scaling (50-50 Split)\n",
    "\n",
    "For experimentation, we also create a **50-50 train-test split** to evaluate model performance on a larger test set.\n",
    "\n",
    "1. **Train-Test Split**:  \n",
    "   - `50%` of data is used for training, `50%` for testing  \n",
    "   - `random_state=42` ensures reproducibility  \n",
    "\n",
    "2. **Feature Scaling**:  \n",
    "   - Standardize features using `StandardScaler` to have **zero mean** and **unit variance**  \n",
    "   - Essential for models like SVM and Logistic Regression, which are sensitive to feature scales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b292ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test ,Y_train, Y_test = train_test_split(X,y,test_size =0.50, random_state=42)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
